{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidsvash26/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_folder = '/home/sidsvash26/kaggle_quora/data/'\n",
    "\n",
    "train_X1 = pickle.load(open(data_folder + 'feats1_tfidf_train.sav', 'rb'))\n",
    "train_X2 = pickle.load(open(data_folder + 'feats2_match_train.sav', 'rb'))\n",
    "train_X3 = pickle.load(open(data_folder + 'feats3_glove_train.sav', 'rb'))\n",
    "train_X4 = pickle.load(open(data_folder + 'feats4_word2vec.sav', 'rb'))\n",
    "train_X6 = pickle.load(open(data_folder + 'feats6_whq_jaccard.sav', 'rb'))\n",
    "train_X10 = pickle.load(open(data_folder + 'feats10_locations.sav', 'rb'))\n",
    "\n",
    "#Magic feats\n",
    "\n",
    "train_X8 = pickle.load(open(data_folder + 'feats8_kcore_v1.sav', 'rb'))\n",
    "train_X9 = pickle.load(open(data_folder + 'feats9_all_magic.sav', 'rb'))\n",
    "\n",
    "#Concatenate all features\n",
    "train_X = np.concatenate((train_X1, train_X2, train_X3, train_X4, train_X6,  train_X8, train_X9, train_X10), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean target rate :  0.163245999318\n",
      "[0]\ttrain-logloss:0.678481\ttest-logloss:0.678523\n",
      "Multiple eval metrics have been passed: 'test-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-logloss hasn't improved in 100 rounds.\n",
      "[10]\ttrain-logloss:0.558897\ttest-logloss:0.55931\n",
      "[20]\ttrain-logloss:0.474895\ttest-logloss:0.475608\n",
      "[30]\ttrain-logloss:0.413094\ttest-logloss:0.414048\n",
      "[40]\ttrain-logloss:0.366517\ttest-logloss:0.367694\n",
      "[50]\ttrain-logloss:0.331245\ttest-logloss:0.332608\n",
      "[60]\ttrain-logloss:0.303882\ttest-logloss:0.305417\n",
      "[70]\ttrain-logloss:0.282095\ttest-logloss:0.283791\n",
      "[80]\ttrain-logloss:0.265329\ttest-logloss:0.267149\n",
      "[90]\ttrain-logloss:0.251436\ttest-logloss:0.25336\n",
      "[100]\ttrain-logloss:0.240428\ttest-logloss:0.242474\n",
      "[110]\ttrain-logloss:0.231652\ttest-logloss:0.233788\n",
      "[120]\ttrain-logloss:0.22432\ttest-logloss:0.226555\n",
      "[130]\ttrain-logloss:0.218021\ttest-logloss:0.220351\n",
      "[140]\ttrain-logloss:0.213069\ttest-logloss:0.215462\n",
      "[150]\ttrain-logloss:0.209007\ttest-logloss:0.211455\n",
      "[160]\ttrain-logloss:0.20562\ttest-logloss:0.208115\n",
      "[170]\ttrain-logloss:0.202638\ttest-logloss:0.205167\n",
      "[180]\ttrain-logloss:0.20023\ttest-logloss:0.202788\n",
      "[190]\ttrain-logloss:0.198098\ttest-logloss:0.200684\n",
      "[200]\ttrain-logloss:0.196308\ttest-logloss:0.198894\n",
      "[210]\ttrain-logloss:0.19468\ttest-logloss:0.19727\n",
      "[220]\ttrain-logloss:0.193286\ttest-logloss:0.195893\n",
      "[230]\ttrain-logloss:0.192\ttest-logloss:0.194605\n",
      "[240]\ttrain-logloss:0.190826\ttest-logloss:0.193442\n",
      "[250]\ttrain-logloss:0.189654\ttest-logloss:0.192286\n",
      "[260]\ttrain-logloss:0.188764\ttest-logloss:0.191405\n",
      "[270]\ttrain-logloss:0.187834\ttest-logloss:0.190479\n",
      "[280]\ttrain-logloss:0.186962\ttest-logloss:0.189615\n",
      "[290]\ttrain-logloss:0.186156\ttest-logloss:0.188822\n",
      "[300]\ttrain-logloss:0.185378\ttest-logloss:0.188046\n",
      "[310]\ttrain-logloss:0.184642\ttest-logloss:0.187306\n",
      "[320]\ttrain-logloss:0.183986\ttest-logloss:0.186666\n",
      "[330]\ttrain-logloss:0.183348\ttest-logloss:0.186031\n",
      "[340]\ttrain-logloss:0.182777\ttest-logloss:0.185475\n",
      "[350]\ttrain-logloss:0.182181\ttest-logloss:0.184902\n",
      "[360]\ttrain-logloss:0.181616\ttest-logloss:0.18435\n",
      "[370]\ttrain-logloss:0.181079\ttest-logloss:0.183832\n",
      "[380]\ttrain-logloss:0.180575\ttest-logloss:0.183345\n",
      "[390]\ttrain-logloss:0.180036\ttest-logloss:0.182819\n",
      "[400]\ttrain-logloss:0.17949\ttest-logloss:0.182289\n",
      "[410]\ttrain-logloss:0.17901\ttest-logloss:0.18182\n",
      "[420]\ttrain-logloss:0.178651\ttest-logloss:0.18148\n",
      "[430]\ttrain-logloss:0.178207\ttest-logloss:0.181043\n",
      "[440]\ttrain-logloss:0.177833\ttest-logloss:0.180685\n",
      "[450]\ttrain-logloss:0.177427\ttest-logloss:0.180299\n",
      "[460]\ttrain-logloss:0.177036\ttest-logloss:0.179929\n",
      "[470]\ttrain-logloss:0.176642\ttest-logloss:0.17956\n",
      "[480]\ttrain-logloss:0.176263\ttest-logloss:0.179193\n",
      "[490]\ttrain-logloss:0.175948\ttest-logloss:0.178892\n",
      "[500]\ttrain-logloss:0.175604\ttest-logloss:0.178579\n",
      "[510]\ttrain-logloss:0.175288\ttest-logloss:0.178287\n",
      "[520]\ttrain-logloss:0.175012\ttest-logloss:0.178027\n",
      "[530]\ttrain-logloss:0.174712\ttest-logloss:0.177749\n",
      "[540]\ttrain-logloss:0.174439\ttest-logloss:0.177486\n",
      "[550]\ttrain-logloss:0.174152\ttest-logloss:0.177217\n",
      "[560]\ttrain-logloss:0.173855\ttest-logloss:0.176942\n",
      "[570]\ttrain-logloss:0.17362\ttest-logloss:0.17672\n",
      "[580]\ttrain-logloss:0.173356\ttest-logloss:0.176473\n",
      "[590]\ttrain-logloss:0.173083\ttest-logloss:0.176217\n",
      "[600]\ttrain-logloss:0.172848\ttest-logloss:0.176007\n",
      "[610]\ttrain-logloss:0.172638\ttest-logloss:0.175813\n",
      "[620]\ttrain-logloss:0.172417\ttest-logloss:0.175614\n",
      "[630]\ttrain-logloss:0.172189\ttest-logloss:0.175395\n",
      "[640]\ttrain-logloss:0.171947\ttest-logloss:0.175165\n",
      "[650]\ttrain-logloss:0.171732\ttest-logloss:0.174964\n",
      "[660]\ttrain-logloss:0.171509\ttest-logloss:0.174755\n",
      "[670]\ttrain-logloss:0.171299\ttest-logloss:0.174564\n",
      "[680]\ttrain-logloss:0.171073\ttest-logloss:0.17437\n",
      "[690]\ttrain-logloss:0.170897\ttest-logloss:0.174215\n",
      "[700]\ttrain-logloss:0.170708\ttest-logloss:0.174046\n",
      "[710]\ttrain-logloss:0.170528\ttest-logloss:0.17389\n",
      "[720]\ttrain-logloss:0.170306\ttest-logloss:0.173687\n",
      "[730]\ttrain-logloss:0.170141\ttest-logloss:0.173532\n",
      "[740]\ttrain-logloss:0.169976\ttest-logloss:0.173386\n",
      "[750]\ttrain-logloss:0.169783\ttest-logloss:0.173221\n",
      "[760]\ttrain-logloss:0.169584\ttest-logloss:0.173045\n",
      "[770]\ttrain-logloss:0.169428\ttest-logloss:0.172909\n",
      "[780]\ttrain-logloss:0.169279\ttest-logloss:0.172794\n",
      "[790]\ttrain-logloss:0.169094\ttest-logloss:0.172629\n",
      "[800]\ttrain-logloss:0.168942\ttest-logloss:0.172504\n",
      "[810]\ttrain-logloss:0.168791\ttest-logloss:0.172373\n",
      "[820]\ttrain-logloss:0.168621\ttest-logloss:0.172217\n",
      "[830]\ttrain-logloss:0.168461\ttest-logloss:0.172075\n",
      "[840]\ttrain-logloss:0.168303\ttest-logloss:0.171939\n",
      "[850]\ttrain-logloss:0.168145\ttest-logloss:0.171802\n",
      "[860]\ttrain-logloss:0.167999\ttest-logloss:0.171677\n",
      "[870]\ttrain-logloss:0.167852\ttest-logloss:0.171555\n",
      "[880]\ttrain-logloss:0.167713\ttest-logloss:0.171439\n",
      "[890]\ttrain-logloss:0.167559\ttest-logloss:0.171301\n",
      "[900]\ttrain-logloss:0.167446\ttest-logloss:0.171208\n",
      "[910]\ttrain-logloss:0.167302\ttest-logloss:0.171084\n",
      "[920]\ttrain-logloss:0.167169\ttest-logloss:0.170974\n",
      "[930]\ttrain-logloss:0.167027\ttest-logloss:0.170855\n",
      "[940]\ttrain-logloss:0.166897\ttest-logloss:0.170737\n",
      "[950]\ttrain-logloss:0.166767\ttest-logloss:0.170636\n",
      "[960]\ttrain-logloss:0.166653\ttest-logloss:0.170546\n",
      "[970]\ttrain-logloss:0.166499\ttest-logloss:0.170406\n",
      "[980]\ttrain-logloss:0.166366\ttest-logloss:0.170292\n",
      "[990]\ttrain-logloss:0.166246\ttest-logloss:0.170195\n",
      "[1000]\ttrain-logloss:0.166103\ttest-logloss:0.170078\n",
      "[1010]\ttrain-logloss:0.165971\ttest-logloss:0.169971\n",
      "[1020]\ttrain-logloss:0.165845\ttest-logloss:0.169866\n",
      "[1030]\ttrain-logloss:0.165731\ttest-logloss:0.169769\n",
      "[1040]\ttrain-logloss:0.165602\ttest-logloss:0.169659\n",
      "[1050]\ttrain-logloss:0.165489\ttest-logloss:0.169573\n",
      "[1060]\ttrain-logloss:0.165386\ttest-logloss:0.169492\n",
      "[1070]\ttrain-logloss:0.165294\ttest-logloss:0.169422\n",
      "[1080]\ttrain-logloss:0.16518\ttest-logloss:0.169327\n",
      "[1090]\ttrain-logloss:0.165056\ttest-logloss:0.16923\n"
     ]
    }
   ],
   "source": [
    "#Load training target variable\n",
    "data = pd.read_csv(data_folder + 'train.csv')\n",
    "train_y = np.array(data.is_duplicate)\n",
    "\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0):\n",
    "        params = {}\n",
    "        params[\"objective\"] = \"binary:logistic\"\n",
    "        params['eval_metric'] = 'logloss'\n",
    "        params[\"eta\"] = 0.02\n",
    "        params[\"subsample\"] = 0.7\n",
    "        params[\"min_child_weight\"] = 1\n",
    "        params[\"colsample_bytree\"] = 0.7\n",
    "        params[\"max_depth\"] = 4\n",
    "        params[\"silent\"] = 1\n",
    "        params[\"seed\"] = seed_val\n",
    "        num_rounds = 1100 \n",
    "        plst = list(params.items())\n",
    "        xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "        if test_y is not None:\n",
    "                xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "                watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "                model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=100, verbose_eval=10)\n",
    "        else:\n",
    "                xgtest = xgb.DMatrix(test_X)\n",
    "                model = xgb.train(plst, xgtrain, num_rounds)\n",
    "                \n",
    "        pred_test_y = model.predict(xgtest)\n",
    "\n",
    "        loss = 1\n",
    "        if test_y is not None:\n",
    "                loss = log_loss(test_y, pred_test_y)\n",
    "                return pred_test_y, loss, model\n",
    "        else:\n",
    "            return pred_test_y, loss, model\n",
    "        \n",
    "#Re-sampling the data\n",
    "train_X_dup = train_X[train_y==1]\n",
    "train_X_non_dup = train_X[train_y==0]\n",
    "\n",
    "train_X = np.vstack([train_X_non_dup, train_X_dup, train_X_non_dup, train_X_non_dup])\n",
    "train_y = np.array([0]*train_X_non_dup.shape[0] + [1]*train_X_dup.shape[0] + [0]*train_X_non_dup.shape[0] + [0]*train_X_non_dup.shape[0])\n",
    "del train_X_dup\n",
    "del train_X_non_dup\n",
    "print(\"Mean target rate : \",train_y.mean())\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "for dev_index, val_index in kf.split(range(train_X.shape[0])):\n",
    "    dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    preds, lloss, model = runXGB(dev_X, dev_y, val_X, val_y)\n",
    "    break\n",
    "\n",
    "pickle.dump(model, open(data_folder + 'model9_feat123468910.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting values\n",
      "predictions done!!\n"
     ]
    }
   ],
   "source": [
    "#Submission Script\n",
    "\n",
    "data_folder = '/home/sidsvash26/kaggle_quora/data/'\n",
    "#Load test data features\n",
    "#For creation of the below pickle see Model4 code above\n",
    "'''  Uncomment if running for the first time -- running the code seperately due to low RAM '''\n",
    "test_X1 = pickle.load(open(data_folder + 'feats1_tfidf_test.sav', 'rb'))\n",
    "test_X2 = pickle.load(open(data_folder + 'feats2_match_test.sav', 'rb'))\n",
    "test_X3 = pickle.load(open(data_folder + 'feats3_glove_test.sav', 'rb'))\n",
    "test_X4 = pickle.load(open(data_folder + 'feats4_word2vec_test.sav', 'rb'))\n",
    "test_X6 = pickle.load(open(data_folder + 'feats6_whq_jaccard_for_test.sav', 'rb'))\n",
    "test_X10 = pickle.load(open(data_folder + 'feats10_locations_for_test.sav', 'rb'))\n",
    "\n",
    "#magic feats\n",
    "test_X8 = pickle.load(open(data_folder + 'feats8_kcore_v1_for_test.sav', 'rb'))\n",
    "test_X9 = pickle.load(open(data_folder + 'feats9_all_magic_for_test.sav', 'rb'))\n",
    "\n",
    "test_X = np.concatenate((test_X1,test_X2,test_X3,test_X4, test_X6,test_X8, test_X9, test_X10), axis=1)\n",
    "\n",
    "xg_model = pickle.load(open(data_folder + 'model9_feat123468910.sav', 'rb')) \n",
    "\n",
    "#Predictions using model\n",
    "xgtest = xgb.DMatrix(test_X)\n",
    "print('predicting values')\n",
    "preds = xg_model.predict(xgtest)\n",
    "print('predictions done!!')\n",
    "#Load test ids\n",
    "test_data = pd.read_csv(data_folder + 'sample_submission.csv')\n",
    "ids = test_data.test_id\n",
    "\n",
    "\n",
    "out_df = pd.DataFrame({\"test_id\": ids, \"is_duplicate\":preds})\n",
    "\n",
    "list_col = out_df.columns.tolist()\n",
    "list_col = list_col[-1:] + list_col[:-1]\n",
    "\n",
    "out_df = out_df[list_col]\n",
    "\n",
    "sub_folder = '/home/sidsvash26/kaggle_quora/submissions/'\n",
    "out_df.to_csv(sub_folder + \"model9_feat123468910.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
